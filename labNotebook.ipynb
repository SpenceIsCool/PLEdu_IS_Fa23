{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51cd7f6",
   "metadata": {},
   "source": [
    "# Lab Notebook\n",
    "* The lab notebook holds summarized notes on the days of research. The intention is to provide some log of the research exploration timeline, the thought process in decision making and various challenges in completing the work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeae1e5",
   "metadata": {},
   "source": [
    "## TEMPLATE: D: Month dd, yyyy (template)\n",
    "- Timeline of completed work\n",
    "- Challenges in completing the work\n",
    "- Documentation of decision processes\n",
    "- should be edited representation of the work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78383ad",
   "metadata": {},
   "source": [
    "## R: Nov 30, 2023\n",
    "Wrapping up my week of discussions with experts I was finally able to take <a href=\"https://plv.colorado.edu/bec/\">Evan Chang's</a> advice and take a meeting where I brought the discussion points and guided the meeting discussion with him as my advisor. Here, my goal was to follow up on the notes from Jessica in deeply understanding the goal instruction goals prior to determining grading mechanisms. Evan describes it at the highest level to provide students the opportunity to demonstrate mastery learning on the course content both by lecturing model as well as a more hands on learning approach with labs that are in sync with the lecture content (as opposed to the typical one week behind the lecture content). He identifies one strength of this teaching method is to give those students who prefer tinkering a better experience then they often have in the standard education models, while continuing to support the traditional learner. We agreed that this often comes with a lot of challenges from the traditional learner against the boundaries that we are forming, and we have to continue to figure out how to handle those discussions as they arise and help to get all of our students as \"co-conspirators\" to this method of learning.\n",
    "\n",
    "As for interview grading, Evan is very aware that the current model isn't perfect and that the interviewers are not domain experts. Accordingly we agree that the interview questions could stand to be reworked and there is potentially value in having the peer to peer interviewing. This lead into a great discussion regarding the goal level of the interviews with respect to the Bloom's Taxonomy. Consider that in Lab 1 of this course students author a solution for an unbalanced binary search tree and validation method (among other things). Then, during interviews the students are asked about implementing a validation method for an AVL tree (a type of balanced binary search tree that CU Boulder typically does not lecture on in pre-requisite courses). While I have been considering this in the Create range of the Bloom's Taxonomy, Evan actually identifies this as a simple \"change of numbers\" in the problem. Here, the change of number is rather than asking students to solve the order invariant of a tree, they now solve the balance invariant of a tree. Given the level of maturity we expect in our students in this upper division class, this could be perceived as a change of numbers and I would likely rank the question as asking the students to \"Analyze\" the problem. Note, this is a higher challenge then what I typically think of as \"changing the numbers\", where I would likely ask students to invert the ordering variant (confirm it is sorted high to low) which I would rank as asking the students to \"Apply\" learning. I feel certain that the current question phrasing for lab 1 doesn't align to this intention, but with some careful consideration in rephrasing the question, I think it would be possible for this to clearly present itself as a change of numbers for the typical student. \n",
    "\n",
    "NOTE: I think Evan has a different picture of the Blooms Taxonomy of learning identifying the peak \"create\" as advanced research on the topic, however, in the literature, a kinder-gardener can \"create\" relative to their own expected level of knowledge, so this is some misalignment on the taxonomy that I need to likely explain better in future writings.\n",
    "\n",
    "QUESTION: In the extreme, what would happen if we assigned grade weightings only to the formative learning? If it's not the end of the world, then could we lower the weighting on the exams? To the extent that the formative learning tools are valuable in preparation for the summative assessments, then why would this be a bad thing? I suppose my personal experience with this is that sometimes are students are not perfect and ethical. My goal in exams is to provide a space where students have to show their mastery of the content without the potential to receive outside help that goes beyond my course policies on collaboration.\n",
    "\n",
    "SUMMARY IDEAS FOR FUTURE TERMS:\n",
    "- Provide a double grading system, take the max of the following two options for each student:\n",
    "    1. the standard syllabus grading scheme that we have been using\n",
    "    1. some pre-defined weighted average of the two exams (with or without redos/corrections and curves)\n",
    "- At the beginning of the semester, help set expectations for the course by showing students the midterm and/or final exam from an old semester (or rather, some exam version that is completely different from what we will give students this semester). Upon further review of this idea, I'd actually recommend that - in the current structure - add to the lab 1 quiz, after students complete the lab 1 quiz and peer grade it, then we show the students what a midterm question of \"changing the numbers\" looks like by showing them a previous semester midterm exam and the lab 1 questions on that exam (or even just a sample of the one question)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21ff74",
   "metadata": {},
   "source": [
    "## W: Nov 29, 2023\n",
    "Today I got to speak with <a href=\"https://www.colorado.edu/cadre/jessica-alzen\">Jessica Alzen</a> a professor in the college of education in working with <a href=\"https://www.colorado.edu/cadre/\">The Center for Assessment, Design, Research and Evaluation (CADRE)</a>. Her research focuses on evaluation of teaching effectiveness and has covered the universities  <a href=\"https://www.colorado.edu/csl/programs/la-program-learning-assistant-program\">Learning Assistants (LA) program</a> during her PostDoc. While this discussion took a turn closer to my own interests in teaching and potential for a PhD in education, a few key insights arose with with respect to this current research project as follows.\n",
    "\n",
    "First, I came to realize that one of the reasons that our interviews suffer is that the interviewer is not really an expert and doesn't know the technical concepts perfectly to explain it to a student that is struggling. In our discussion we agreed that the value add proposition from the course staff doesn't end at technical expertise for the course, but also comes from this \"more advanced\" learner working with the \"less advanced\" leaner. Potentially working on those soft skill in communication and working with the students to better learn how to solve complex problems. This is highlighted when looking at the goals of the LA program where the student teacher is trained to not solve the problem for people, but only to ask prodding questions that help the student solve the problem for themselves.\n",
    "\n",
    "Additionally, we discussed the method for grading students in the course. As I understood it, she recommends being goal oriented. Define the learning goals of the course first and make sure these are the right goals and that you're ready to defend those goals. Once that is done, you ask what is the purpose of grades in supporting the course goals. Finally you can align grade weighting to the artifacts of the course. e.g. the goal is student concept mastery and grades are a representation of that mastery, so grade weights are given mostly to the tasks which demonstrate the mastery. I'm still not clear on how that informs the weighting for interview grading, but I will explore that more in the future.\n",
    "\n",
    "- NOTE: <a href=\"https://www.colorado.edu/csl/programs/dber-discipline-based-education-research\"> DBER Discipline Based Education Research</a> is a working group that may not have met for a while now, but exists to discuss good teaching practices. Many of the members have been from the sciences over the years.\n",
    "- POC: <a href=\"https://www.colorado.edu/tribalstem/ian-her-many-horses\">Ian Her Many Horses</a> has a background in CS an expert in education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93258526",
   "metadata": {},
   "source": [
    "## T: Nov 28, 2023\n",
    "Today I got to speak with <a href=\"https://www.colorado.edu/education/lorrie-shepard\">Lorrie Shepard</a>, a professor in the college of education regarding her research with relation to my own work. Through the discussion a few key insights are highlighted for me. \n",
    "\n",
    "First, as Lorrie puts it, we don't just get students to \"buy in\", but rather to be our \"co-conspirators\" in this method of learning. As discussed previously in my writings, this method of teaching is a cultural shift and so a non-trivial amount of time must be spent in getting the participants to buy in. Lorrie notes that a lot of the theory often works well in the lab setting while the researcher is present and then it falls apart as the researcher leaves and the teacher often reverts to their \"old ways\". Lorrie identifies this as a lack of understanding of the theory. She suggests that we could learn the theory and even present it in the classroom along with our standard content to give students our reasoning behind our teaching decisions. Tying it to PL, I think we have a very serious challenge in buy in from the top. For this method to succeed, all of the course staff needs continued training on the value of the method of learning and that time needs to come from some coach, be it the professor, or perhaps some assistance from the CTL. Relatedly, I think of Evans concept of being \"warm but firm\". We as the course staff set boundaries, but the students are going to try and push against those boundaries. We must hold the boundary and explain our reasoning backed by the evidence based theory, but we can be nice while we do it.\n",
    "\n",
    "Second, while I was focused on helping students identify what they do not know ad what resources they need to succeed, this is actually an anti-pattern I've learned in HCI and it's an anti-pattern in learning. In HCI, you don't ask the participants what is wrong with the tool, you do not ask them what features they want to see. Instead you observe what the participant does and note the mistakes that are made and the success that are achieved. You might ask clarifying questions to better understand the participants mental model of your tool. Similar concepts apply here in education. Here I'll focus only on the self reflection component of the interviews. We can shift the reflection questions to ask the students to identify which topics they understand well. Here, the students get to celebrate where they have succeeded. We then, on the back end, know what they did not do well on. We are able to take what they did do well on, and build on that to improve their mastery of the other topics. \n",
    "\n",
    "Finally, a topic that I continue to struggle with is the matter of grading. Lorrie confirms that in the literature gradings is mostly negative for motivation as it is extrinsic and we wish to achieve intrinsic motivators for the students. So my question is, do we grade the interview at all? Do the students bother with an N/A/P/AU grade? I know that in my midterm reflection it was clear that a letter grade is a hard ask of a student, and even this 4 point system is pretty intimidating to me despite my own background knowledge on the system. I think that here, for my research I'd recommend that we keep the 4 point system grading on the interview so students have some unified scalable system for grading. This then helps the student understand where they are at with the material and aligns better to their current mental model of education systems. The interview is that formative assessment and safe space scaffolding in which students attempt to answer complex questions and gauge their own ability to answer the questions. Then they have identified where they are succeeding and struggling and they have the agency to seek further assistance before the evaluative assessment like an exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7de7df",
   "metadata": {},
   "source": [
    "## R: Nov 16, 2023\n",
    "Today I explored the real data that I would gather from students. The students are given a brief survey at the midterm and final to collect their own approximation of their best ability to perform within the blooms taxonomy. We also have the students performance data in the course. Using both of these we can design some weighted score of students performance and and plot the students success in a heatmap throughout the control, pilot and experiment data. Below is my sample heatmap built with seaborn.heatmap. We observe that the highest weighting of student performance in the control group is \"understand\" and moves up two levels to \"analyze\" in the experiment group. More work needs to be done to beautify the heatmap for presentation and some work needs to be considered on how we normalize the data as this heatmap actually charts student weighted percentages rather than the raw data. I think there is a good case to be made that this data would embed some findings for student equity and demonstrate that some specific groups see outpaced performance gains in the experiment than other groups. e.g. she/her,they/them compared to he/him data is analyzed for a statistically evident R-value (NOTE: she/her is grouped with they/them as there would not be enough students identifying as they/them to have enough data to represent that independently in a statistically meaningful way).\n",
    "\n",
    "<img src=\"./img/toy_heatmap.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea53266",
   "metadata": {},
   "source": [
    "## M: Nov 13, 2023\n",
    "<a href=\"https://www.colorado.edu/education/william-penuel\">Prof Penuel</a> got back already and has offered to connect me with current students on CoBi to discuss the potential for a thesis. While I'm not currently looking for a thesis, I'm interested to discuss the tool further and learn more, so I have reached back to \"Bill\". Continuing on finding a professor to speak with I went searching for a third POC. <a href=\"https://www.colorado.edu/cadre/jessica-alzen\">Prof. Jessica Alzen</a> looks very promising as a member of faculty that *actually* works on post-secondary education and has a lot of recent publications on <a href=\"https://www.tandfonline.com/doi/full/10.1080/26939169.2023.2191666\">collaboration</a>, as well as a fairly recent work on <a href=\"https://link.springer.com/article/10.1007/s10755-021-09554-w\">student coaching</a>. I began work on an email to Prof Alzen, but I'm not quite ready to send it.\n",
    "\n",
    "In very exciting news, I did hear back from <a href=\"https://www.colorado.edu/education/lorrie-shepard\">Prof Lorrie Shepard</a> and she is willing to meet after the fall break. I look forward to following up with her. I believe that Prof. Alzen is a better fit for my current research question, but I'm very interested in talking with Prof. Shepard regarding my personal interests in teaching at scale in an effective and culturally informed way. In some ways, I feel that the article of hers that I read demonstrates that my current research question and proposed solution is short cited and should be considered for rework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963887e",
   "metadata": {},
   "source": [
    "## U: Nov 12, 2023\n",
    "As I explore potential faculty in the department of education to reach out to for discussions on my research, I found a few very interesting papers that give me ideas for how to expand my own research. First \"<a href=\"https://dl.acm.org/doi/pdf/10.1145/3584931.3607498\">The Community Builder (CoBi): Helping Students to Develop Better Small Group Collaborative Learning Skills</a>\" explores the use of a tool that integrates Ai to reviewing student dialog captured in the classroom to help in measuring student engagement and the balance of dialog across many students. The current tool is centered on use in a middle school classroom around discussions about the value and shortcomings of current Ai tools. It's unclear to me how the tool is set up from a technical perspective so I'm unsure how it could be used in a 300 person classroom effectively, but I see it having value in recitation sections up to 40 students and I see how the tool could potentially be used in automated review of peer interview videos to help assess how effectively the students host a converstation together and how the students could work more effectively together. I reached out to Prof. Penuel to see if he'd be interested to discuss further how this could be used to help create better student teams and what impacts this could have on the equity for students in the class.\n",
    "\n",
    "Second \"<a href=\"https://www.aft.org/ae/fall2021/shepard\">Ambitious Teaching and Equitable Assessment</a>\" discusses the issues in standardization in K-12 education policy since the 1980s. These progression of these policies greatly influence the quality of education in our students and any inequities in that system. Beyond the reading, these policies influence the way that many students are used to learning and what they expect in the classroom and do have an impact on college education. So we must consider this in discussions about how to improve college classrooms. The article goes on to discuss a better solution centered around a culturally informed education model that invites students to participate in constructing the learning goals of the class and centers compassion in the classroom. I find that the paper discusses many of the concepts that I have in my own mind about effective education such as peer learning, reflective learning, flexible assignments and leveraging students \"funds of knowledge\". The paper is packed with good references that I need to follow up on for my own writing. However, the paper is centered on K-12 learning and policy, so I envision in focuses on much smaller classrooms. I wonder how these policies can be applied to a 300 student classroom. What about the concept is easy to scale? What about it is hard to scale, but worth the effort? I've reached out the Prof. Shepard about this over email to see if she would be willing to discuss that further. Candidly, with her emeritus status, I'm not optimistic that I'll hear back from her, but it was worth reaching out. I may yet be surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
