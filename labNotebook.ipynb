{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51cd7f6",
   "metadata": {},
   "source": [
    "# Lab Notebook\n",
    "* The lab notebook holds summarized notes on the days of research. The intention is to provide some log of the research exploration timeline, the thought process in decision making and various challenges in completing the work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeae1e5",
   "metadata": {},
   "source": [
    "## TEMPLATE: D: Month dd, yyyy (template)\n",
    "- Timeline of completed work\n",
    "- Challenges in completing the work\n",
    "- Documentation of decision processes\n",
    "- should be edited representation of the work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d3856-b0f1-4a7b-b247-257b8169542d",
   "metadata": {},
   "source": [
    "## January 23, 2024\n",
    "As usual I'm having trouble launching this new semester of independent study. To get started I have taken time to re-organize the GitHub repository to make this semester easier to run. Additionally I have started to re-read some of those key works that I cited last semester to refresh myself on the ideas that I want to pursue this semester.\n",
    "\n",
    "In reading <a href=\"https://www.alfiekohn.org/article/case-grades/\">Alfie Kohn's \"The Case Against Grading\"</a> I had an interesting observation regarding grades at the end of a course that is largely ungraded. Last semester, my independent study was largely ungraded with a midterm and final self reflection and one on one with the advisor (Evan) to assess my work from a cross semester perspective with the occasional 1:1 meeting that embedded some feedback about my current performance in the independent study. I found that this caused me a decent amount of stress about my grade. I had it in my mind for some reason that Evan doesn't give A's and that I'll get a B or something in the course. While true, Evan requires that you earn your grade, it's not unheard of that people earn an A from him. I won't comment here what my final grade was, but sufficive to say, I am satisfied with the final result. What's interesting to me though, is now that I'm on the other side, and I've seen that I can earn a sufficient mark in an independent study, I now don't care that much about the grade. I have seen that I can do \"good enough\" work and I feel that I can better embrace the un-grading philosophy to focus on doing my work to a sufficient standard without spending as much time worrying about if the work is good enough. As I see it Evan's philosophy (like many in the un-grading camp) is that people will do their best work when they are pushed to their \"zone of proximal development\" without being told explicitly \"you've done the bare minimum to receive X grade\". But I feel that I personally would have performed better if I had known sooner that my work could be \"good enough\" and spent less time stressing about this. While a part of this is simply having students embrace 'un-grading' this inspires a question for me: Can we push students to their peak development in an environment that that causes less stress?\n",
    "\n",
    "Applying this to my current research, I'm thinking about how we can establish standards for the peer to peer interviews that help the students recognize and celebrate what they do know as opposed to getting bogged down by their inability to answer the questions that they don't yet know how to solve. How could the interviews be adaptive to show the students what they know, and then give them a new question based on their performance to the first one? I'm not sure it will be in scope for this semester's independent study, but I want to tinker with it more before I move on to other readings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8974187",
   "metadata": {},
   "source": [
    "## M: Dec 13, 2023\n",
    "Lately I've been thinking a lot about what I'd like my independent study work to focus on in Spring 2024. I'm struggling to pin this down exactly, but the short version is that Chemistry and Physics have a long history in producing great education and studying how their science discipline is taught. CU Boulder even has a full research section in the Physics department dedicated to the <a href=\"https://www.colorado.edu/physics/research/physics-education-research\">education of Physics at the post-secondary level</a>. Does there exist such a research group in CS Education at the post-secondary level in the US (that I could complete a PhD with)? Can I plug in with the Physics department at CU and learn from their findings? What about their discipline is unique that wouldn't transfer well to CS and what is common ground? What would an independent study on this topic look like? I have lots of questions at this time and very few answers, but I thought it best to document some summary of those questions here in the lab notebook as it is on my mind and may find its way into my final presentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7adeb",
   "metadata": {},
   "source": [
    "## R: Dec 7, 2023\n",
    "Discussed at stand up, as I do the writing I'm not disappointed in my writing, but I do see how the writing would be better if I got feedback sooner. This would require writing parts of the paper and being comfortable getting feedback on that unfinished work. One recommendation from Shawn is to consider using the graduate writing center. In particular is can be helpful to sign up for multiple sessions with the same person so they can learn about your work and understand the story that you are trying to convey. I feel this fits nicely into Evan's point that research is having discussions and reading is having discussions with people from the past. If you never have the writing reviewed and you don't get feedback from a brain that isn't yours, then you don't know if you are conveying the points that you really want to make. Having meetings with the writing center can help you stay accountable to not hiding behind the words, but instead lay bare the science that you wish to express.\n",
    "\n",
    "Ultimately I did decided to just fake it. I realized that original heatmap that I proposed earlier in this document is not a sufficient visualization of individual student improved performance across a semester, but instead a confusion matrix would be best. With the original heatmap I have data about the full student population, their proposed scores and their \"true\" scores. But that fails to capture the individual students correctness in assessing their scores. By moving to a confusion matrix, we have data about individual students and their proposed vs real scores. Below is the visualization of this used to suggest that students in the peer to peer interview process are more successful in guessing their true cognition level with the material.\n",
    "\n",
    "<img src=\"./Img/img_compositeCmpWeight.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925d790",
   "metadata": {},
   "source": [
    "## W: Dec 6, 2023\n",
    "It's been challenging to start writing as I've had a variety of other commitments the past few days and I find that writing requires dedicated longer time blocks for me to be able to write down everything that I want to say. In doing the writing I've found a few things. First, I realized that with the new data and desire to change the method of gathering student data and analyzing performance, I'm was not sure what it is that I'm trying to show with the data, after a lot of writing I settled on these four tasks with respect to the impact of peer to peer interview grading:\n",
    "1. What impact does this have on students' completion of the course?\n",
    "1. What impact does this have on students' ability to correctly assess their own performance?\n",
    "1. What impact does this have on student performance?\n",
    "1. What impact does this have on student satisfaction with the course?\n",
    "\n",
    "In creating visualizations of the data, I've realized that I need better graphs and I'm struggling to code this in a good way in python for the real data, I think I'll have to fake it rather than dummying up the data perfectly in a way that python is coded well to solve the problem. This is due to time constraints, but in the future, I think it will be best to really simulate the expected data in CSV files based on expected result averages with good outliers built in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78383ad",
   "metadata": {},
   "source": [
    "## R: Nov 30, 2023\n",
    "Wrapping up my week of discussions with experts I was finally able to take <a href=\"https://plv.colorado.edu/bec/\">Evan Chang's</a> advice and take a meeting where I brought the discussion points and guided the meeting discussion with him as my advisor. Here, my goal was to follow up on the notes from Jessica in deeply understanding the goal instruction goals prior to determining grading mechanisms. Evan describes it at the highest level to provide students the opportunity to demonstrate mastery learning on the course content both by lecturing model as well as a more hands on learning approach with labs that are in sync with the lecture content (as opposed to the typical one week behind the lecture content). He identifies one strength of this teaching method is to give those students who prefer tinkering a better experience then they often have in the standard education models, while continuing to support the traditional learner. We agreed that this often comes with a lot of challenges from the traditional learner against the boundaries that we are forming, and we have to continue to figure out how to handle those discussions as they arise and help to get all of our students as \"co-conspirators\" to this method of learning.\n",
    "\n",
    "As for interview grading, Evan is very aware that the current model isn't perfect and that the interviewers are not domain experts. Accordingly we agree that the interview questions could stand to be reworked and there is potentially value in having the peer to peer interviewing. This lead into a great discussion regarding the goal level of the interviews with respect to the Bloom's Taxonomy. Consider that in Lab 1 of this course students author a solution for an unbalanced binary search tree and validation method (among other things). Then, during interviews the students are asked about implementing a validation method for an AVL tree (a type of balanced binary search tree that CU Boulder typically does not lecture on in pre-requisite courses). While I have been considering this in the Create range of the Bloom's Taxonomy, Evan actually identifies this as a simple \"change of numbers\" in the problem. Here, the change of number is rather than asking students to solve the order invariant of a tree, they now solve the balance invariant of a tree. Given the level of maturity we expect in our students in this upper division class, this could be perceived as a change of numbers and I would likely rank the question as asking the students to \"Analyze\" the problem. Note, this is a higher challenge then what I typically think of as \"changing the numbers\", where I would likely ask students to invert the ordering variant (confirm it is sorted high to low) which I would rank as asking the students to \"Apply\" learning. I feel certain that the current question phrasing for lab 1 doesn't align to this intention, but with some careful consideration in rephrasing the question, I think it would be possible for this to clearly present itself as a change of numbers for the typical student. \n",
    "\n",
    "NOTE: I think Evan has a different picture of the Blooms Taxonomy of learning identifying the peak \"create\" as advanced research on the topic, however, in the literature, a kinder-gardener can \"create\" relative to their own expected level of knowledge, so this is some misalignment on the taxonomy that I need to likely explain better in future writings.\n",
    "\n",
    "QUESTION: In the extreme, what would happen if we assigned grade weightings only to the formative learning? If it's not the end of the world, then could we lower the weighting on the exams? To the extent that the formative learning tools are valuable in preparation for the summative assessments, then why would this be a bad thing? I suppose my personal experience with this is that sometimes are students are not perfect and ethical. My goal in exams is to provide a space where students have to show their mastery of the content without the potential to receive outside help that goes beyond my course policies on collaboration.\n",
    "\n",
    "SUMMARY IDEAS FOR FUTURE TERMS:\n",
    "- Provide a double grading system, take the max of the following two options for each student:\n",
    "    1. the standard syllabus grading scheme that we have been using\n",
    "    1. some pre-defined weighted average of the two exams (with or without redos/corrections and curves)\n",
    "- At the beginning of the semester, help set expectations for the course by showing students the midterm and/or final exam from an old semester (or rather, some exam version that is completely different from what we will give students this semester). Upon further review of this idea, I'd actually recommend that - in the current structure - add to the lab 1 quiz, after students complete the lab 1 quiz and peer grade it, then we show the students what a midterm question of \"changing the numbers\" looks like by showing them a previous semester midterm exam and the lab 1 questions on that exam (or even just a sample of the one question)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21ff74",
   "metadata": {},
   "source": [
    "## W: Nov 29, 2023\n",
    "Today I got to speak with <a href=\"https://www.colorado.edu/cadre/jessica-alzen\">Jessica Alzen</a> a professor in the college of education in working with <a href=\"https://www.colorado.edu/cadre/\">The Center for Assessment, Design, Research and Evaluation (CADRE)</a>. Her research focuses on evaluation of teaching effectiveness and has covered the universities  <a href=\"https://www.colorado.edu/csl/programs/la-program-learning-assistant-program\">Learning Assistants (LA) program</a> during her PostDoc. While this discussion took a turn closer to my own interests in teaching and potential for a PhD in education, a few key insights arose with with respect to this current research project as follows.\n",
    "\n",
    "First, I came to realize that one of the reasons that our interviews suffer is that the interviewer is not really an expert and doesn't know the technical concepts perfectly to explain it to a student that is struggling. In our discussion we agreed that the value add proposition from the course staff doesn't end at technical expertise for the course, but also comes from this \"more advanced\" learner working with the \"less advanced\" leaner. Potentially working on those soft skill in communication and working with the students to better learn how to solve complex problems. This is highlighted when looking at the goals of the LA program where the student teacher is trained to not solve the problem for people, but only to ask prodding questions that help the student solve the problem for themselves.\n",
    "\n",
    "Additionally, we discussed the method for grading students in the course. As I understood it, she recommends being goal oriented. Define the learning goals of the course first and make sure these are the right goals and that you're ready to defend those goals. Once that is done, you ask what is the purpose of grades in supporting the course goals. Finally you can align grade weighting to the artifacts of the course. e.g. the goal is student concept mastery and grades are a representation of that mastery, so grade weights are given mostly to the tasks which demonstrate the mastery. I'm still not clear on how that informs the weighting for interview grading, but I will explore that more in the future.\n",
    "\n",
    "- NOTE: <a href=\"https://www.colorado.edu/csl/programs/dber-discipline-based-education-research\"> DBER Discipline Based Education Research</a> is a working group that may not have met for a while now, but exists to discuss good teaching practices. Many of the members have been from the sciences over the years.\n",
    "- POC: <a href=\"https://www.colorado.edu/tribalstem/ian-her-many-horses\">Ian Her Many Horses</a> has a background in CS an expert in education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93258526",
   "metadata": {},
   "source": [
    "## T: Nov 28, 2023\n",
    "Today I got to speak with <a href=\"https://www.colorado.edu/education/lorrie-shepard\">Lorrie Shepard</a>, a professor in the college of education regarding her research with relation to my own work. Through the discussion a few key insights are highlighted for me. \n",
    "\n",
    "First, as Lorrie puts it, we don't just get students to \"buy in\", but rather to be our \"co-conspirators\" in this method of learning. As discussed previously in my writings, this method of teaching is a cultural shift and so a non-trivial amount of time must be spent in getting the participants to buy in. Lorrie notes that a lot of the theory often works well in the lab setting while the researcher is present and then it falls apart as the researcher leaves and the teacher often reverts to their \"old ways\". Lorrie identifies this as a lack of understanding of the theory. She suggests that we could learn the theory and even present it in the classroom along with our standard content to give students our reasoning behind our teaching decisions. Tying it to PL, I think we have a very serious challenge in buy in from the top. For this method to succeed, all of the course staff needs continued training on the value of the method of learning and that time needs to come from some coach, be it the professor, or perhaps some assistance from the CTL. Relatedly, I think of Evans concept of being \"warm but firm\". We as the course staff set boundaries, but the students are going to try and push against those boundaries. We must hold the boundary and explain our reasoning backed by the evidence based theory, but we can be nice while we do it.\n",
    "\n",
    "Second, while I was focused on helping students identify what they do not know ad what resources they need to succeed, this is actually an anti-pattern I've learned in HCI and it's an anti-pattern in learning. In HCI, you don't ask the participants what is wrong with the tool, you do not ask them what features they want to see. Instead you observe what the participant does and note the mistakes that are made and the success that are achieved. You might ask clarifying questions to better understand the participants mental model of your tool. Similar concepts apply here in education. Here I'll focus only on the self reflection component of the interviews. We can shift the reflection questions to ask the students to identify which topics they understand well. Here, the students get to celebrate where they have succeeded. We then, on the back end, know what they did not do well on. We are able to take what they did do well on, and build on that to improve their mastery of the other topics. \n",
    "\n",
    "Finally, a topic that I continue to struggle with is the matter of grading. Lorrie confirms that in the literature gradings is mostly negative for motivation as it is extrinsic and we wish to achieve intrinsic motivators for the students. So my question is, do we grade the interview at all? Do the students bother with an N/A/P/AU grade? I know that in my midterm reflection it was clear that a letter grade is a hard ask of a student, and even this 4 point system is pretty intimidating to me despite my own background knowledge on the system. I think that here, for my research I'd recommend that we keep the 4 point system grading on the interview so students have some unified scalable system for grading. This then helps the student understand where they are at with the material and aligns better to their current mental model of education systems. The interview is that formative assessment and safe space scaffolding in which students attempt to answer complex questions and gauge their own ability to answer the questions. Then they have identified where they are succeeding and struggling and they have the agency to seek further assistance before the evaluative assessment like an exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7de7df",
   "metadata": {},
   "source": [
    "## R: Nov 16, 2023\n",
    "Today I explored the real data that I would gather from students. The students are given a brief survey at the midterm and final to collect their own approximation of their best ability to perform within the blooms taxonomy. We also have the students performance data in the course. Using both of these we can design some weighted score of students performance and and plot the students success in a heatmap throughout the control, pilot and experiment data. Below is my sample heatmap built with seaborn.heatmap. We observe that the highest weighting of student performance in the control group is \"understand\" and moves up two levels to \"analyze\" in the experiment group. More work needs to be done to beautify the heatmap for presentation and some work needs to be considered on how we normalize the data as this heatmap actually charts student weighted percentages rather than the raw data. I think there is a good case to be made that this data would embed some findings for student equity and demonstrate that some specific groups see outpaced performance gains in the experiment than other groups. e.g. she/her,they/them compared to he/him data is analyzed for a statistically evident R-value (NOTE: she/her is grouped with they/them as there would not be enough students identifying as they/them to have enough data to represent that independently in a statistically meaningful way).\n",
    "\n",
    "<img src=\"./img/toy_heatmap.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea53266",
   "metadata": {},
   "source": [
    "## M: Nov 13, 2023\n",
    "<a href=\"https://www.colorado.edu/education/william-penuel\">Prof Penuel</a> got back already and has offered to connect me with current students on CoBi to discuss the potential for a thesis. While I'm not currently looking for a thesis, I'm interested to discuss the tool further and learn more, so I have reached back to \"Bill\". Continuing on finding a professor to speak with I went searching for a third POC. <a href=\"https://www.colorado.edu/cadre/jessica-alzen\">Prof. Jessica Alzen</a> looks very promising as a member of faculty that *actually* works on post-secondary education and has a lot of recent publications on <a href=\"https://www.tandfonline.com/doi/full/10.1080/26939169.2023.2191666\">collaboration</a>, as well as a fairly recent work on <a href=\"https://link.springer.com/article/10.1007/s10755-021-09554-w\">student coaching</a>. I began work on an email to Prof Alzen, but I'm not quite ready to send it.\n",
    "\n",
    "In very exciting news, I did hear back from <a href=\"https://www.colorado.edu/education/lorrie-shepard\">Prof Lorrie Shepard</a> and she is willing to meet after the fall break. I look forward to following up with her. I believe that Prof. Alzen is a better fit for my current research question, but I'm very interested in talking with Prof. Shepard regarding my personal interests in teaching at scale in an effective and culturally informed way. In some ways, I feel that the article of hers that I read demonstrates that my current research question and proposed solution is short cited and should be considered for rework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963887e",
   "metadata": {},
   "source": [
    "## U: Nov 12, 2023\n",
    "As I explore potential faculty in the department of education to reach out to for discussions on my research, I found a few very interesting papers that give me ideas for how to expand my own research. First \"<a href=\"https://dl.acm.org/doi/pdf/10.1145/3584931.3607498\">The Community Builder (CoBi): Helping Students to Develop Better Small Group Collaborative Learning Skills</a>\" explores the use of a tool that integrates Ai to reviewing student dialog captured in the classroom to help in measuring student engagement and the balance of dialog across many students. The current tool is centered on use in a middle school classroom around discussions about the value and shortcomings of current Ai tools. It's unclear to me how the tool is set up from a technical perspective so I'm unsure how it could be used in a 300 person classroom effectively, but I see it having value in recitation sections up to 40 students and I see how the tool could potentially be used in automated review of peer interview videos to help assess how effectively the students host a converstation together and how the students could work more effectively together. I reached out to Prof. Penuel to see if he'd be interested to discuss further how this could be used to help create better student teams and what impacts this could have on the equity for students in the class.\n",
    "\n",
    "Second \"<a href=\"https://www.aft.org/ae/fall2021/shepard\">Ambitious Teaching and Equitable Assessment</a>\" discusses the issues in standardization in K-12 education policy since the 1980s. These progression of these policies greatly influence the quality of education in our students and any inequities in that system. Beyond the reading, these policies influence the way that many students are used to learning and what they expect in the classroom and do have an impact on college education. So we must consider this in discussions about how to improve college classrooms. The article goes on to discuss a better solution centered around a culturally informed education model that invites students to participate in constructing the learning goals of the class and centers compassion in the classroom. I find that the paper discusses many of the concepts that I have in my own mind about effective education such as peer learning, reflective learning, flexible assignments and leveraging students \"funds of knowledge\". The paper is packed with good references that I need to follow up on for my own writing. However, the paper is centered on K-12 learning and policy, so I envision in focuses on much smaller classrooms. I wonder how these policies can be applied to a 300 student classroom. What about the concept is easy to scale? What about it is hard to scale, but worth the effort? I've reached out the Prof. Shepard about this over email to see if she would be willing to discuss that further. Candidly, with her emeritus status, I'm not optimistic that I'll hear back from her, but it was worth reaching out. I may yet be surprised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
