{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05511a4e-bc91-4cf7-a85f-7533ced79d93",
   "metadata": {},
   "source": [
    "# DATA participant 15 interview 1\n",
    "1. consent\n",
    "    1. took about 18 minutes\n",
    "    2. Questions about what if the participant knows other participants in the focus group, does that impact the research study? No, it won't impact the research study, however it is something to consider upon consent in the focus group. Consider if you want to openly discuss your experiences of the course with these peers that you know.\n",
    "    3. Questions about the reporting of academic integrity issues, is the researcher required to report matter of academic dishonesty? No, the researcher will not and shall not report matters of academic dishonesty. The researcher is however, required as a mandatory reporter to report matters of sexual misconduct and violence involving CU persons to OIEC. The researcher can provide the participant with a full description of the reporting requirements and explain those requirements at any time.\n",
    "2. Interview\n",
    "    1. Q1: As a student in 3155, what was your experience working with a \"lab partner\" on your labs? Please elaborate.\n",
    "       1. The participant reports that they would often work with partners on projects in person. They would pair program on the projects, however there was often some two types of partners for pair programming. Some project partners would do all of the coding work and ignore the participants recommendation for contributions. Some project partners would effectively refuse to contribute ideas or solutions for the project. The participant reports that the project partners were always one of these two kinds of partners.\n",
    "       2. The participant reports that their biggest challenges was that they could not get the development environment working on their local machine and were instead required to code on VSCode hosted on JupyterHub at coding.csel.io. \n",
    "       3. The participant notes that they and their partners would often not leverage the power of github. They would often pair program together and push the results once finished.\n",
    "    2. Q2: As a student in 3155, you had interview grading with a member of the course staff. What was your typical process to prepare for this interview? Did it evolve over the course of the semester?\n",
    "       1. The participant describes challenges in understanding how to interpret inference rules and further challenges in relating those rules to code.\n",
    "       2. The participant explains how as the semester evolved they and their peers would intentionally aim for an interview slot in the middle of the available slots so they could crowd-source questions from their peers who took the earlier slots. The people that would take the interview early would often tell others what the questions .\n",
    "       3. FOLLOWUP: For clarity, as you worked with your peers to know the questions for the interviews, did you also try to learn the answers to those questions from your peers?\n",
    "           1. The participant describes some nuance of the typical experience in crowd-sourcing questions and answers. Students would often share what their own answer to the interview questions were, however those students did not have confidence that their answer was correct and accordingly the next student would not attend the interview with confidence in what the correct answer is despite having privileged knowledge of the interview questions. The participant goes on to explain that 'Professor Chang' promoted collaboration in the course and students felt comfortable sharing information like this with their peers. Students felt unsure if this was a violation of course policy, perhaps primarily as no student seemed certain what the correct answer to the interview questions actually were.\n",
    "       4. QUOTATION: \"Solicitation was never truly helpful.\"\n",
    "    3. Q3: As a student in 3155, what was your experience working with a \"grader\" for your interviews at the end of the lab? Please elaborate.\n",
    "       1. The participant finds the question amusing. **question why?**\n",
    "       2. The participant explains that \"all of the staff tried their best\" to help students where they could. Each member of the course staff would \"attempt\" to explain concepts to student in the course. However, the students \"never quite got it\". As the semester progressed the students fell further and further behind on the requisite knowledge for the next topic in the course to the point that it felt like the course staff could not be effective in explaining topics to the students. Eventually the sentiment of this participant and some of their peers was: \"Those are the answers, lets move on.\"\n",
    "    4. Q4: What impact, if any, did the interviews have on your confidence to succeed in the course?\n",
    "        1. The participant details how each successive interview made their confidence worsen until the transition from lab 5 to lab 6. Since lab 5 was maybe the peak of learning inference rules but then lab 6 looked at understanding and working with regular expressions which made more sense to the participant.\n",
    "        2. FOLLOWUP: Would you describe that as linear or exponential?\n",
    "            1. The participant describes the increase in the challenge of each 2 weeks of lab content as linear. Specifically, it felt that way in the moment. However they also recall feeling fairly lost for most of the course.\n",
    "    5. Q5: Do you have experiences with interview grading in other courses? If so, how did those experiences compare to your experience in 3155?\n",
    "        1. The participant explains their past experience with interview grading in Computer Systems. In that course most of the interview questions had the student explain their own code and would rarely ask the student about conceptual topics of the course. However in PPL there were some theory questions that had a big disconnect for students as the textbook did not always connect to the conceptual knowledge needed for success.\n",
    "        2. The participant notes that they would have performed better on the interviews if the interview questions were only about the code that they had already written.\n",
    "        3. The participant also notes a difference in the percentage value of assignments between these courses, with computer systems have 42% labs, 48% exams (12% each by 4 exams), and 10% for recitations. Compared against the PL standard.\n",
    "            1. CONFIRMED: Fall 2022 CSCI 3155 syllabus: labs 30% (5% each), exercises (10%), class participation (5%), midterm exam (25%), final exam (30%).\n",
    "    6. Q6: What would you describe as your learning goal for 3155?\n",
    "        1. QUOTATION: \"The only information I had was from my academic advisor that said it shouldn't be a challenging class.\"\n",
    "        2. The participant describes the first day of class, and hearing the professor describe how we could learn syntax and then build up a compiler for Scala that made Scala behave as though it were JavaScript. The participant states that it sounded really interesting to make a language work like another language and was excited to learn that. However, the participant failed in meeting that goal as they felt lost throughout the course.\n",
    "3. Post interview question in followup and data review\n",
    "    1.  One more clarifying question for you: When asked about question 3 \"As a student in 3155, what was your experience working with a \"grader\" for your interviews at the end of the lab? Please elaborate\". You seemed amused by the question. Why was that\n",
    "        1.  RESPONSE: I felt that it was amusing as the it seemed that graders were aware of the minimal understanding the students had regarding the topics during the process of the grading. In some cases, I felt that the graders had to attempt to help us by giving us multiple hints or even straight up teach students certain concepts during the grading to assist them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce476c-0c77-4e06-bd46-936ba984ce3b",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "* Interesting point regarding the expectation of collaboration in the course.\n",
    "* The apply student: often felt that partners would evaluate or remember would not work well with them in pair programming. In an interview this student might be in a poor position to work with others. They note that \"Solicitation was never truly helpful.\" And so maybe the interview with peers with solutions and walkthroughs could give a lot of value to the student and their peers. This would even the playing field in that the apply student should be able to read the questions and solutions well enough to hold their own in asking the evaluate student about some topic and the nuance within that topic. I'm not sure that I have or can address how the remember student engages with the content, but I do think that the participant concern about how the graders handle the gradin ginterview is better addressed in this model. Yes, sometimes you get to the interview and you still need to learn the information as you didn't learn it during the lab. This is a feature, not abug. By providing questions, followups, hints, and solutions we provide students a flexible envrionment to learn on their terms. My hope is that the evaluate student will do their best to help the apply or remember student learn, but I can't impose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
